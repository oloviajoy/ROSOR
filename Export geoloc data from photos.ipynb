{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f910e5e-f623-4ff6-8a73-e0c5336b0334",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shapely'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point, shape\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfiona\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shapely'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from shapely.geometry import Point, shape\n",
    "import fiona\n",
    "import numpy as np\n",
    "\n",
    "input_photo_folder = r\"F:\\LM2403-66 Dahrouge EGNC\\Pix4DMatic processing\\Eleonore 1\\exports\"\n",
    "\n",
    "\n",
    "# Suppress DecompressionBombWarning\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def get_exif_data(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    exif_data = image._getexif()\n",
    "    if not exif_data:\n",
    "        return None\n",
    "\n",
    "    exif = {}\n",
    "    for tag, value in exif_data.items():\n",
    "        decoded = TAGS.get(tag, tag)\n",
    "        exif[decoded] = value\n",
    "    return exif\n",
    "\n",
    "def get_gps_data(image_path):\n",
    "    exif_data = get_exif_data(image_path)\n",
    "    gps_info = {}\n",
    "    for key in exif_data['GPSInfo'].keys():\n",
    "        decode = GPSTAGS.get(key, key)\n",
    "        gps_info[decode] = exif_data['GPSInfo'][key]\n",
    "    latitude, longitude = extract_lat_lon(gps_info)\n",
    "    return latitude, longitude\n",
    "\n",
    "def convert_to_degrees(value):\n",
    "    d, m, s = value\n",
    "    return d + (m / 60.0) + (s / 3600.0)\n",
    "\n",
    "def extract_lat_lon(gps_data):\n",
    "    lat = None\n",
    "    lon = None\n",
    "    if gps_data:\n",
    "        gps_latitude = gps_data.get('GPSLatitude')\n",
    "        gps_latitude_ref = gps_data.get('GPSLatitudeRef')\n",
    "        gps_longitude = gps_data.get('GPSLongitude')\n",
    "        gps_longitude_ref = gps_data.get('GPSLongitudeRef')\n",
    "\n",
    "        if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n",
    "            lat = convert_to_degrees(gps_latitude)\n",
    "            if gps_latitude_ref != 'N':\n",
    "                lat = -lat\n",
    "\n",
    "            lon = convert_to_degrees(gps_longitude)\n",
    "            if gps_longitude_ref != 'E':\n",
    "                lon = -lon\n",
    "\n",
    "    return lat, lon\n",
    "\n",
    "def get_list_of_paths_os_walk_folder(folder_path, ext):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            if os.path.splitext(filename)[1].lower() == ext.lower():\n",
    "                file_path = os.path.join(root, filename)\n",
    "                file_paths.append(file_path)\n",
    "\n",
    "    def natural_sort_key(s):\n",
    "        # This function will create a sort key that handles numbers properly\n",
    "        return [int(text) if text.isdigit() else text.lower() for text in re.split('(\\d+)', s)]\n",
    "\n",
    "    file_paths.sort(key=natural_sort_key)\n",
    "    return file_paths\n",
    "\n",
    "def get_name_of_non_existing_output_file(base_filepath, additional_suffix='', new_extention=''):\n",
    "    # Function to create a unique file path by adding a version number\n",
    "    base, ext = os.path.splitext(base_filepath)\n",
    "    if new_extention:\n",
    "        ext = new_extention\n",
    "    new_out_file_path = f\"{base}{additional_suffix}{ext}\"\n",
    "\n",
    "    if not os.path.exists(new_out_file_path):\n",
    "        return new_out_file_path\n",
    "\n",
    "    version = 2\n",
    "    while os.path.exists(f\"{base}{additional_suffix}_v{version}{ext}\"):\n",
    "        version += 1\n",
    "    return f\"{base}{additional_suffix}_v{version}{ext}\"\n",
    "\n",
    "def save_to_csv(output_csv_file, *args, column_names=None):\n",
    "    # Check if all lists have the same length\n",
    "    if not all(len(lst) == len(args[0]) for lst in args):\n",
    "        print(\"Error: All input lists must be of the same length.\")\n",
    "        return\n",
    "\n",
    "    # Set default column names if none are provided\n",
    "    if column_names is None:\n",
    "        column_names = ['Column' + str(i+1) for i in range(len(args))]\n",
    "    elif len(column_names) != len(args):\n",
    "        print(\"Error: Number of column names must match number of input lists.\")\n",
    "        return\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(output_csv_file, mode='w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header row based on the provided or default column names\n",
    "        csv_writer.writerow(column_names)\n",
    "\n",
    "        # Write the data rows\n",
    "        for row in zip(*args):\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "    print(f\"Data has been saved to {output_csv_file}\")\n",
    "\n",
    "\n",
    "def get_photos_in_polygons(tile_polygon_paths, lat_list, lon_list, photo_paths):\n",
    "    # Initialize the boolean mask list with False values\n",
    "    boolean_mask_dict = {}\n",
    "\n",
    "    for tile_polygon_path in tile_polygon_paths:\n",
    "        boolean_mask = [False] * len(photo_paths)\n",
    "        # Open the shapefile and iterate over its features\n",
    "        with fiona.open(tile_polygon_path) as shapefile:\n",
    "            print('new shp')\n",
    "            for feature in shapefile:\n",
    "                polygon = shape(feature['geometry'])\n",
    "\n",
    "                # Check each photo's coordinates\n",
    "                for i, (lat, lon, photo_path) in enumerate(zip(lat_list, lon_list, photo_paths)):\n",
    "                    point = Point(lon, lat)\n",
    "                    if polygon.contains(point):\n",
    "                        boolean_mask[i] = True\n",
    "                        print(f'Photo {photo_path} is in a polygon.')\n",
    "                    else:\n",
    "                        print(f'Photo {photo_path} is not in a polygon.')\n",
    "        boolean_mask_dict[tile_polygon_path] = boolean_mask\n",
    "    return boolean_mask_dict\n",
    "\n",
    "\n",
    "photo_paths = get_list_of_paths_os_walk_folder(input_photo_folder, '.tiff')\n",
    "\n",
    "lat_list, lon_list = [], []\n",
    "for path in photo_paths:\n",
    "    latitude, longitude = get_gps_data(path)\n",
    "    #print(f\"Latitude: {latitude}, Longitude: {longitude}\")\n",
    "    lat_list.append(latitude)\n",
    "    lon_list.append(longitude)\n",
    "\n",
    "if not len(lat_list) == len(lon_list) == len(photo_paths) > 0:\n",
    "    raise ValueError\n",
    "\n",
    "boolean_mask_dict = get_photos_in_polygons(tile_polygon_paths, lat_list, lon_list, photo_paths)\n",
    "for poly_path, mask in boolean_mask_dict.items():\n",
    "    print(poly_path, mask)\n",
    "    name = os.path.join(os.path.dirname(os.path.dirname(poly_path)), os.path.basename(poly_path))\n",
    "    output_csv_file = get_name_of_non_existing_output_file(name,\n",
    "                                                           additional_suffix='_photo_locations',\n",
    "                                                           new_extention='.csv')\n",
    "    poly_paths =  np.array(photo_paths)[mask].tolist()\n",
    "    poly_lons = np.array(lon_list)[mask].tolist()\n",
    "    poly_lats =  np.array(lat_list)[mask].tolist()\n",
    "    save_to_csv(output_csv_file, poly_paths, poly_lons, poly_lats, column_names=['Name', 'Longitude', 'Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f396b9b9-4bbb-4057-92a7-96c9a43b1c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from shapely.geometry import Point, shape\n",
    "import fiona\n",
    "import numpy as np\n",
    "\n",
    "input_photo_folder = r\"F:\\LM2403-66 Dahrouge EGNC\\Photos within flightlines\\Eleonore flight 2\"\n",
    "\n",
    "\n",
    "# Suppress DecompressionBombWarning\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def get_exif_data(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    exif_data = image._getexif()\n",
    "    if not exif_data:\n",
    "        return None\n",
    "\n",
    "    exif = {}\n",
    "    for tag, value in exif_data.items():\n",
    "        decoded = TAGS.get(tag, tag)\n",
    "        exif[decoded] = value\n",
    "    return exif\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed4822cd-d90f-4ab0-914b-b00fd3c718c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gps_data(image_path):\n",
    "    exif_data = get_exif_data(image_path)\n",
    "    gps_info = {}\n",
    "    for key in exif_data['GPSInfo'].keys():\n",
    "        decode = GPSTAGS.get(key, key)\n",
    "        gps_info[decode] = exif_data['GPSInfo'][key]\n",
    "    latitude, longitude = extract_lat_lon(gps_info)\n",
    "    return latitude, longitude\n",
    "\n",
    "def convert_to_degrees(value):\n",
    "    d, m, s = value\n",
    "    return d + (m / 60.0) + (s / 3600.0)\n",
    "\n",
    "def extract_lat_lon(gps_data):\n",
    "    lat = None\n",
    "    lon = None\n",
    "    if gps_data:\n",
    "        gps_latitude = gps_data.get('GPSLatitude')\n",
    "        gps_latitude_ref = gps_data.get('GPSLatitudeRef')\n",
    "        gps_longitude = gps_data.get('GPSLongitude')\n",
    "        gps_longitude_ref = gps_data.get('GPSLongitudeRef')\n",
    "\n",
    "        if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n",
    "            lat = convert_to_degrees(gps_latitude)\n",
    "            if gps_latitude_ref != 'N':\n",
    "                lat = -lat\n",
    "\n",
    "            lon = convert_to_degrees(gps_longitude)\n",
    "            if gps_longitude_ref != 'E':\n",
    "                lon = -lon\n",
    "\n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fa5a84a-30dd-4a35-bc22-2eedcc350916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_paths_os_walk_folder(folder_path, ext):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            if os.path.splitext(filename)[1].lower() == ext.lower():\n",
    "                file_path = os.path.join(root, filename)\n",
    "                file_paths.append(file_path)\n",
    "\n",
    "    def natural_sort_key(s):\n",
    "        # This function will create a sort key that handles numbers properly\n",
    "        return [int(text) if text.isdigit() else text.lower() for text in re.split('(\\d+)', s)]\n",
    "\n",
    "    file_paths.sort(key=natural_sort_key)\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3bcf995-5067-472e-94b6-8412fb4d699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_of_non_existing_output_file(base_filepath, additional_suffix='', new_extention=''):\n",
    "    # Function to create a unique file path by adding a version number\n",
    "    base, ext = os.path.splitext(base_filepath)\n",
    "    if new_extention:\n",
    "        ext = new_extention\n",
    "    new_out_file_path = f\"{base}{additional_suffix}{ext}\"\n",
    "\n",
    "    if not os.path.exists(new_out_file_path):\n",
    "        return new_out_file_path\n",
    "\n",
    "    version = 2\n",
    "    while os.path.exists(f\"{base}{additional_suffix}_v{version}{ext}\"):\n",
    "        version += 1\n",
    "    return f\"{base}{additional_suffix}_v{version}{ext}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "101515cc-8e57-46fb-a2b8-05bfdb548a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_to_csv(output_csv_file, *args, column_names=None):\n",
    "    # Check if all lists have the same length\n",
    "    if not all(len(lst) == len(args[0]) for lst in args):\n",
    "        print(\"Error: All input lists must be of the same length.\")\n",
    "        return\n",
    "# Set default column names if none are provided\n",
    "    if column_names is None:\n",
    "        column_names = ['Column' + str(i+1) for i in range(len(args))]\n",
    "    elif len(column_names) != len(args):\n",
    "        print(\"Error: Number of column names must match number of input lists.\")\n",
    "        return\n",
    "\n",
    "    # Open the CSV file for writing\n",
    "    with open(output_csv_file, mode='w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "\n",
    "        # Write the header row based on the provided or default column names\n",
    "        csv_writer.writerow(column_names)\n",
    "\n",
    "        # Write the data rows\n",
    "        for row in zip(*args):\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "    print(f\"Data has been saved to {output_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe36f53b-199c-4900-a9b0-eee58a881869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_photos_in_polygons(tile_polygon_paths, lat_list, lon_list, photo_paths):\n",
    "    # Initialize the boolean mask list with False values\n",
    "    boolean_mask_dict = {}\n",
    "\n",
    "    for tile_polygon_path in tile_polygon_paths:\n",
    "        boolean_mask = [False] * len(photo_paths)\n",
    "        # Open the shapefile and iterate over its features\n",
    "        with fiona.open(tile_polygon_path) as shapefile:\n",
    "            print('new shp')\n",
    "            for feature in shapefile:\n",
    "                polygon = shape(feature['geometry'])\n",
    "\n",
    "                # Check each photo's coordinates\n",
    "                for i, (lat, lon, photo_path) in enumerate(zip(lat_list, lon_list, photo_paths)):\n",
    "                    point = Point(lon, lat)\n",
    "                    if polygon.contains(point):\n",
    "                        boolean_mask[i] = True\n",
    "                        print(f'Photo {photo_path} is in a polygon.')\n",
    "                    else:\n",
    "                        print(f'Photo {photo_path} is not in a polygon.')\n",
    "        boolean_mask_dict[tile_polygon_path] = boolean_mask\n",
    "    return boolean_mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a637b06c-a264-44af-81f5-d516b1f1d44c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     lon_list\u001b[38;5;241m.\u001b[39mappend(longitude)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lat_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(lon_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(photo_paths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[0;32m     13\u001b[0m boolean_mask_dict \u001b[38;5;241m=\u001b[39m get_photos_in_polygons(tile_polygon_paths, lat_list, lon_list, photo_paths)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m poly_path, mask \u001b[38;5;129;01min\u001b[39;00m boolean_mask_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "photo_paths = get_list_of_paths_os_walk_folder(input_photo_folder, '.tiff')\n",
    "\n",
    "lat_list, lon_list = [], []\n",
    "for path in photo_paths:\n",
    "    latitude, longitude = get_gps_data(path)\n",
    "    #print(f\"Latitude: {latitude}, Longitude: {longitude}\")\n",
    "    lat_list.append(latitude)\n",
    "    lon_list.append(longitude)\n",
    "\n",
    "if not len(lat_list) == len(lon_list) == len(photo_paths) > 0:\n",
    "    raise ValueError\n",
    "\n",
    "boolean_mask_dict = get_photos_in_polygons(tile_polygon_paths, lat_list, lon_list, photo_paths)\n",
    "for poly_path, mask in boolean_mask_dict.items():\n",
    "    print(poly_path, mask)\n",
    "    name = os.path.join(os.path.dirname(os.path.dirname(poly_path)), os.path.basename(poly_path))\n",
    "    output_csv_file = get_name_of_non_existing_output_file(name,\n",
    "                                                           additional_suffix='_photo_locations',\n",
    "                                                           new_extention='.csv')\n",
    "    poly_paths =  np.array(photo_paths)[mask].tolist()\n",
    "    poly_lons = np.array(lon_list)[mask].tolist()\n",
    "    poly_lats =  np.array(lat_list)[mask].tolist()\n",
    "    save_to_csv(output_csv_file, poly_paths, poly_lons, poly_lats, column_names=['Name', 'Longitude', 'Latitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c12d4-7f14-4f32-86b2-6d25420ade6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
